# GPU Architecture Comparison - RDNA vs VLIW

**Objective**: Understand the difference between our RDNA driver and the FreeBSD VLIW driver needed for Haiku  

---

## Executive Summary

| Aspect | Our RDNA (Navi10) | FreeBSD VLIW (HD 7290) |
|--------|------------------|----------------------|
| **Target Hardware** | Modern discrete GPU | Old integrated GPU |
| **Architecture** | Modern, simplified | Old, complex |
| **Instruction Format** | Packet-based | 128-bit VLIW bundles |
| **Ring Buffers** | Modern, simple | Classic, complex |
| **Frequency Range** | 1000-2000 MHz | 400-800 MHz |
| **Compute Model** | Wave64 (64 work items) | VLIW4 (4 ops per cycle) |
| **Complexity** | Medium | High |

---

## Architecture Details

### RDNA (Our Current Driver)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Modern Ring-Based (RDNA)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Features:                         â”‚
â”‚ âœ… Packet-based commands         â”‚
â”‚ âœ… Simplified instruction set    â”‚
â”‚ âœ… Modern power management       â”‚
â”‚ âœ… Advanced memory VM            â”‚
â”‚ âœ… Complex scheduling            â”‚
â”‚ âœ… High performance              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Instruction: Simple packet
â”œâ”€ Type: 32-bit packet
â”œâ”€ Header: Type + size
â””â”€ Data: Command payload

Ring: Modern circular queue
â”œâ”€ Write pointer: CPU updates
â”œâ”€ Read pointer: GPU updates
â””â”€ Fence: Completion tracking
```

### VLIW (FreeBSD HD 7290)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Classic VLIW-Based              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Features:                         â”‚
â”‚ âŒ VLIW instruction encoding     â”‚
â”‚ âŒ Complex scheduling            â”‚
â”‚ âœ… Simple memory management      â”‚
â”‚ âš ï¸ Legacy power states           â”‚
â”‚ âŒ Multiple ALUs per cycle       â”‚
â”‚ âš ï¸ Lower frequency (800MHz max)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Instruction: 128-bit VLIW bundle
â”œâ”€ ALU0: 32-bit operation
â”œâ”€ ALU1: 32-bit operation
â”œâ”€ ALU2: 32-bit operation
â””â”€ ALU3: 32-bit operation

Ring: Classic command buffer
â”œâ”€ Write pointer: CPU updates
â”œâ”€ Read pointer: GPU updates
â””â”€ Flags: Status bits (no fence)
```

---

## Command Submission Comparison

### RDNA (Ours) - Simple Packets

```c
// Packet format
struct rdna_packet {
    uint32_t header;      // Type + size
    uint32_t cmd1;        // Command data
    uint32_t cmd2;
    uint32_t cmd3;
};

// Submission
ring_write(ring, packet, 4);  // 4 dwords
ring_doorbell(write_ptr);      // Wake GPU
fence = ring_alloc_fence();    // Track completion
```

### VLIW (FreeBSD) - Complex VLIW Bundles

```c
// VLIW instruction format (128 bits)
struct vliw_instruction {
    uint32_t alu0;        // ALU 0 operation
    uint32_t alu1;        // ALU 1 operation
    uint32_t alu2;        // ALU 2 operation
    uint32_t alu3;        // ALU 3 operation
};

// Complex scheduling needed
// Compiler must arrange 4 ops per cycle
// Dependencies between ALUs
// Register hazards
```

---

## 2D Operations Comparison

### RDNA: Simple 2D Packets

```c
// Build BLIT packet
struct blit_packet {
    uint32_t header;      // BLIT type
    uint32_t src_base;    // Source address
    uint32_t dst_base;    // Dest address
    uint32_t width;       // Size
    uint32_t height;
    uint32_t pitch;       // Bytes per row
};

// Submit: 1 packet = 1 operation
ring_write(ring, packet);
```

### VLIW: Complex VLIW Scheduling

```c
// Build VLIW instructions for BLIT
struct vliw_instruction instructions[8];  // Multiple ops

// Need to schedule:
instructions[0].alu0 = load_src_address();
instructions[0].alu1 = load_pitch();
instructions[0].alu2 = setup_write_buffer();
instructions[0].alu3 = calculate_offsets();

instructions[1].alu0 = iterate_pixels();
instructions[1].alu1 = read_pixel();
instructions[1].alu2 = write_pixel();
instructions[1].alu3 = increment_counters();

// Complex: Dependencies, hazards, stalls
```

---

## Memory Management Comparison

### RDNA: Advanced VM

```c
// Virtual Memory Support
struct vm_context {
    page_table_base;        // Root of page tables
    vm_context_id;          // Per-process ID
    translation_lookaside;  // TLB for translations
};

// Automatic address translation
gpu_addr = vm_translate(cpu_addr);  // Automatic
```

### VLIW: Basic Addressing

```c
// Direct physical addressing mostly
// Minimal VM support
struct phys_address {
    phys_base;              // Physical address
    size;                   // Size
};

// Manual address calculation
gpu_addr = physical_base + offset;  // Manual
```

---

## Ring Buffer Comparison

### RDNA Ring

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Write Ptr (CPU) â†’ Ring â† Read Ptr (GPU)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“
  Fence Value
     â†“
  GPU posts fence #5
     â†“
  CPU polls for fence #5
     â†“
  Work done âœ“
```

### VLIW Ring

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Write Ptr (CPU) â†’ Ring â† Read Ptr (GPU)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“
  Status Flags
     â†“
  GPU sets BUSY flag
     â†“
  CPU polls BUSY flag
     â†“
  GPU clears BUSY flag
     â†“
  Work done âœ“
```

---

## Performance Characteristics

### RDNA Performance
- **Throughput**: 1-2 TFLOPs (FP32)
- **Frequency**: 1000-2000 MHz
- **Latency**: Low (modern design)
- **Power**: 100-200W

### VLIW Performance
- **Throughput**: 50-100 GFLOPs (4 ops/cycle @ 800MHz)
- **Frequency**: 400-800 MHz
- **Latency**: High (older design)
- **Power**: 5-15W (integrated)

---

## Code Complexity Comparison

### RDNA: Simpler Code

```
File Count: 10-15 files
Lines per file: 200-500 lines
Total: ~3,000 lines
Complexity: Medium (packets, modern features)
```

### VLIW: More Complex Code

```
File Count: 20-30 files
Lines per file: 300-1000 lines  
Total: ~8,000 lines
Complexity: High (VLIW scheduling, legacy code)
```

---

## Which Driver for Haiku?

### Current Situation

**Machine in Meeting (Modern)**:
- Probably has RDNA/NAVI GPU
- Our driver applies directly âœ…
- ~2,500 lines implemented
- Performance: Good

**Haiku Machine (Old)**:
- Has HD 7290 (VLIW)
- Needs FreeBSD adaptation
- ~8,000 lines to port
- Performance: Limited but usable

### Recommendation

1. **Our RDNA driver**: Use as-is for modern hardware
2. **FreeBSD VLIW adapter**: Create separate for HD 7290
   - Could share:
     - Display/CRTC layer
     - Accelerant interface
     - OS abstractions
   - Different:
     - GPU command submission
     - 2D/3D operations
     - Power management

---

## Development Path Forward

### Option A: Support Both

```
AMDGPU_Abstracted/
â”œâ”€ src/amd/hal/
â”‚  â”œâ”€ gfx_navi10.c    (RDNA) âœ…
â”‚  â”œâ”€ gfx_r600.c      (VLIW) â³
â”‚  â””â”€ ...
```

Effort: +20-30 hours for VLIW support

### Option B: Focus on RDNA (Modern Hardware)

```
AMDGPU_Abstracted/ (RDNA only)
â”œâ”€ Current implementation âœ…
```

Effort: None additional

### Option C: Separate Projects

```
AMDGPU_Abstracted/ (RDNA)
FreeBSD_Radeon_Adapter/ (VLIW)
```

Effort: Split work, cleaner separation

---

## Conclusion

| Scenario | Driver Choice |
|----------|--------------|
| Modern GPU (RDNA) | âœ… Use current driver |
| Old GPU (VLIW) | âš ï¸ Adapt FreeBSD code |
| Both support | ðŸŽ¯ Modular approach |

The FreeBSD reference files are now available for VLIW architecture study and adaptation.

---

**Last Updated**: Jan 17 2026  
**Status**: Reference complete, ready for VLIW implementation planning

# Unified AMD GPU Driver Architecture

**Status**: Design Document - Comprehensive Refactor  
**Scope**: Multi-generational, Multi-backend Driver  
**Timeline**: Phase 1 (Reference), Phase 2-4 (Implementation)  
**Platforms**: Linux, FreeBSD (drm-kmod), Haiku  
**GPU Support**: VLIW (2000-6000) â†’ RDNA2 (5700 XT, Lucienne, etc.)

---

## Executive Summary

Instead of separate abstractions for SI/CIK, create a **unified, modular AMD GPU driver** that:

1. **Supports entire AMD GPU lineage** (2005-2024)
2. **Dynamic backend selection** (RADV/Vulkan for modern, Mesa/OpenGL for legacy)
3. **Based on drm-kmod structure** as reference architecture
4. **Single driver entry point** with pluggable components
5. **Tested on real hardware** (Lucienne/RDNA2 locally, Wrestler/VLIW on Haiku)

### Your Hardware

```
Local (Linux - Artix):
  GPU: Lucienne (Renoir)
  Device: [1002:164c]
  Architecture: RDNA 2 (modern)
  Capabilities: RADV (Vulkan) native support
  Role: Testing modern path

Remote (Haiku):
  GPU: Radeon HD 7290 (Wrestler)
  Device: [1002:9806]
  Architecture: VLIW2 (legacy)
  Capabilities: OpenGL only
  Role: Testing legacy path
```

---

## Design Philosophy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         UNIFIED AMD GPU DRIVER ARCHITECTURE                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  Device Probe & Detection                                â”‚
â”‚  â”œâ”€ PCI device ID matching                               â”‚
â”‚  â”œâ”€ Hardware capabilities assessment                      â”‚
â”‚  â””â”€ Generation classification (VLIW/SI/CIK/GCN/RDNA)     â”‚
â”‚                                                            â”‚
â”‚  GPU Abstraction Layer (HAL)                             â”‚
â”‚  â”œâ”€ Abstract IP block management                          â”‚
â”‚  â”œâ”€ Unified register access                              â”‚
â”‚  â””â”€ Common memory management                             â”‚
â”‚                                                            â”‚
â”‚  Generation-Specific Handlers                            â”‚
â”‚  â”œâ”€ VLIW handler (GFX, DCE, memory)                      â”‚
â”‚  â”œâ”€ GCN handler (SI/CIK/Polaris/Vega)                   â”‚
â”‚  â””â”€ RDNA handler (RDNA/RDNA2)                           â”‚
â”‚                                                            â”‚
â”‚  Backend Selection                                        â”‚
â”‚  â”œâ”€ RADV (Vulkan) - if GPU supports compute              â”‚
â”‚  â”œâ”€ Mesa Gallium (OpenGL) - fallback                     â”‚
â”‚  â””â”€ Software rendering - if hardware disabled            â”‚
â”‚                                                            â”‚
â”‚  Platform Abstraction                                     â”‚
â”‚  â”œâ”€ Linux: KMS/DRM interface                             â”‚
â”‚  â”œâ”€ FreeBSD: drm-kmod bridge                             â”‚
â”‚  â””â”€ Haiku: Custom accelerant + subsystem                 â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## GPU Generation Map

### Complete AMD GPU Timeline

```
Generation     Timeline   Arch      Codenames                  Driver
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
VLIW           2005-2012  VLIW4/2   R700, Northern Islands    radeon
               (legacy)             Wrestler, Zacate

SI (GCN1)      2012-2013  GCN v1    Tahiti, Pitcairn, Verde  radeon/amdgpu
CIK (GCN2)     2013-2014  GCN v2    Bonaire, Hawaii, Kaveri  radeon/amdgpu

GCN3           2015       GCN v3    Fiji, Polaris             amdgpu
GCN4           2016       GCN v4    Vega, Arcturus            amdgpu
GCN5           2019       GCN v5    RDNA                      amdgpu

RDNA           2020       RDNA 1    RX 5700 XT                amdgpu
RDNA2          2020-2021  RDNA 2    RX 6800, Lucienne*        amdgpu â† YOUR HW
RDNA3          2022       RDNA 3    RX 7900 XT                amdgpu

* Lucienne = APU with RDNA 2 integrated GPU
```

### Generation Classification Strategy

```c
enum amd_gpu_generation {
    AMD_VLIW,       // VLIW4/2 (radeon driver only)
    AMD_GCN1,       // Southern Islands
    AMD_GCN2,       // Sea Islands
    AMD_GCN3,       // Fiji, Polaris
    AMD_GCN4,       // Vega
    AMD_GCN5,       // RDNA generation 1
    AMD_RDNA2,      // RDNA generation 2 (your hardware)
    AMD_RDNA3,      // RDNA generation 3
};

enum amd_backend_type {
    AMD_BACKEND_RADV,           // Vulkan (RDNA+ native)
    AMD_BACKEND_MESA_GALLIUM,   // OpenGL (universal fallback)
    AMD_BACKEND_LLVMPIPE,       // Software rendering (last resort)
};
```

---

## Modular Architecture

### Layer 1: Device Detection & Classification

```c
// In: PCI device ID
// Out: GPU info (generation, capabilities, backend)

struct amd_gpu_device {
    uint16_t vendor_id;         // 0x1002 (AMD)
    uint16_t device_id;         // PCI device ID
    
    enum amd_gpu_generation gen;
    const char *codename;       // "Lucienne", "Tahiti", etc.
    const char *marketing_name; // "Radeon RX 6700", etc.
    
    struct {
        bool has_radv;          // Can use RADV (Vulkan)
        bool has_mesa_gallium;  // Can use Mesa (OpenGL)
        bool has_compute;       // Compute shader support
        bool has_raytracing;    // Ray tracing support
    } capabilities;
    
    enum amd_backend_type preferred_backend;
    
    struct amd_gpu_handler *handler;  // Generation-specific functions
};
```

### Layer 2: GPU Handler (Generation-Specific)

```c
struct amd_gpu_handler {
    // Core
    int (*hw_init)(struct amd_device *dev);
    int (*hw_fini)(struct amd_device *dev);
    
    // IP Block Management
    int (*init_ip_blocks)(struct amd_device *dev);
    int (*enable_ip_block)(struct amd_device *dev, int block_type);
    
    // Memory Management
    int (*init_gmc)(struct amd_device *dev);
    int (*allocate_vram)(struct amd_device *dev, size_t size, 
                         uint64_t *gpu_addr);
    
    // Graphics
    int (*init_gfx)(struct amd_device *dev);
    int (*submit_command)(struct amd_device *dev, 
                          struct cmd_buffer *cmd);
    
    // Display
    int (*init_dce)(struct amd_device *dev);
    int (*set_display_mode)(struct amd_device *dev,
                            struct display_mode *mode);
    
    // Cleanup
    void (*cleanup_ip_blocks)(struct amd_device *dev);
};
```

### Layer 3: Backend Abstraction (RADV vs Mesa)

```c
// Backend abstraction for API-specific operations
struct amd_api_backend {
    const char *name;  // "RADV", "Mesa Gallium", "LLVMPipe"
    
    // Shader compilation
    int (*compile_shader)(const char *glsl_source,
                          void **spirv_binary, size_t *size);
    
    // Resource binding
    int (*create_buffer)(struct amd_device *dev, size_t size,
                         struct gpu_buffer **buf);
    int (*bind_texture)(struct amd_device *dev,
                        struct gpu_texture *tex);
    
    // Rendering
    int (*draw_primitives)(struct amd_device *dev,
                           struct draw_call *dc);
    int (*submit_compute_job)(struct amd_device *dev,
                              struct compute_kernel *kernel);
};
```

### Layer 4: Platform Bridge

```c
// Abstraction for Linux KMS, FreeBSD drm-kmod, Haiku subsystem
struct amd_platform_bridge {
    // Device registration
    int (*register_device)(struct amd_device *dev);
    int (*unregister_device)(struct amd_device *dev);
    
    // Memory management
    int (*request_vram)(size_t size, uint64_t *gpu_addr);
    int (*release_vram)(uint64_t gpu_addr);
    
    // Display integration
    int (*set_framebuffer)(uint64_t gpu_addr, uint32_t width,
                           uint32_t height, uint32_t stride);
    
    // Power management
    int (*enter_power_state)(int power_level);
    int (*exit_power_state)(void);
};
```

---

## Device Database Structure

### Database File Format

```
// src/amd/amd_devices.c - Complete GPU device database

struct amd_device_entry {
    uint16_t device_id;
    enum amd_gpu_generation generation;
    const char *codename;
    const char *marketing_name;
    uint32_t max_compute_units;
    uint32_t max_vram;
    struct {
        bool radv_support;
        bool mesa_support;
        bool raytracing;
    } capabilities;
    struct amd_gpu_handler *handler;
};

static const struct amd_device_entry amd_devices[] = {
    // VLIW
    { 0x9806, AMD_VLIW, "Wrestler", "Radeon HD 7290", 
      2, 2048, {false, true, false}, &vliw_handler },
    
    // SI (Southern Islands)
    { 0x6798, AMD_GCN1, "Tahiti", "Radeon HD 7970",
      32, 3072, {false, true, false}, &gcn1_handler },
    
    // RDNA2 (Your hardware)
    { 0x164c, AMD_RDNA2, "Lucienne", "Radeon",
      8, 2048, {true, true, true}, &rdna2_handler },
};
```

---

## Implementation Roadmap

### Phase 1: Architecture & Reference (Current)

**Output**: This document + reference implementation

```
AMDGPU_Abstracted/
â”œâ”€â”€ src/amd/
â”‚   â”œâ”€â”€ amd_device.h/c         # Core device abstraction
â”‚   â”œâ”€â”€ amd_handlers.h/c       # Generation-specific handlers
â”‚   â”œâ”€â”€ amd_devices_db.c       # Complete device database
â”‚   â”œâ”€â”€ amd_backends.h/c       # RADV/Mesa backend abstraction
â”‚   â””â”€â”€ amd_platform.h/c       # Linux/FreeBSD/Haiku bridge
â”‚
â”œâ”€â”€ handlers/
â”‚   â”œâ”€â”€ vliw_handler.c         # VLIW implementation
â”‚   â”œâ”€â”€ gcn1_handler.c         # SI (GCN1) implementation
â”‚   â”œâ”€â”€ rdna2_handler.c        # RDNA2 implementation
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ docs/
    â””â”€â”€ UNIFIED_AMD_DRIVER_ARCHITECTURE.md
```

### Phase 2: Linux Integration (1-2 weeks)

- [ ] Integrate with Linux DRM/KMS
- [ ] Test with Lucienne (RDNA2) locally
- [ ] RADV (Vulkan) path
- [ ] Mesa (OpenGL) fallback

### Phase 3: FreeBSD/drm-kmod Port (1 week)

- [ ] Port to drm-kmod bridge
- [ ] Test compilation and basic functionality
- [ ] Reference drm-kmod code as needed

### Phase 4: Haiku & Legacy Support (2-3 weeks)

- [ ] VLIW handler implementation
- [ ] Haiku accelerant integration
- [ ] Test with Wrestler (VLIW)
- [ ] SI/CIK support completion

### Phase 5: Testing & Hardening (1-2 weeks)

- [ ] Full test suite across all generations
- [ ] Dual-system testing (Linux + Haiku)
- [ ] Performance optimization
- [ ] Edge case handling

---

## Driver Entry Points

### Linux Entry Point (amdgpu_pci_probe equivalent)

```c
// src/amd/amd_pci.c

int amd_pci_probe(struct pci_dev *pdev, ...) {
    struct amd_gpu_device gpu_info;
    
    // Step 1: Detect GPU
    if (amd_detect_gpu(pdev->device, &gpu_info) < 0) {
        return -ENODEV;  // Not an AMD GPU we support
    }
    
    // Step 2: Check if we should handle it
    if (amd_should_defer_to_legacy_driver(&gpu_info)) {
        dev_info(&pdev->dev, "%s support provided by %s driver",
                 gpu_info.codename, gpu_info.preferred_driver);
        return -ENODEV;  // Let radeon or amdgpu handle it
    }
    
    // Step 3: Initialize device
    struct amd_device *dev = amd_device_alloc(&gpu_info);
    if (!dev) return -ENOMEM;
    
    if (dev->handler->hw_init(dev) < 0) {
        amd_device_free(dev);
        return -ENODEV;
    }
    
    // Step 4: Select and initialize backend
    if (gpu_info.capabilities.radv_support) {
        dev->backend = amd_backend_radv_init(dev);
    } else {
        dev->backend = amd_backend_mesa_init(dev);
    }
    
    if (!dev->backend) {
        dev->handler->hw_fini(dev);
        amd_device_free(dev);
        return -ENODEV;
    }
    
    // Step 5: Register with platform
    if (amd_platform_register_device(dev) < 0) {
        dev->backend->cleanup(dev);
        dev->handler->hw_fini(dev);
        amd_device_free(dev);
        return -ENODEV;
    }
    
    dev_info(&pdev->dev, "AMD %s (%s) [%04x:%04x] initialized with %s backend",
             gpu_info.marketing_name, gpu_info.codename,
             gpu_info.vendor_id, gpu_info.device_id,
             dev->backend->name);
    
    return 0;
}
```

### FreeBSD/drm-kmod Integration

```c
// Reference drm-kmod structure in:
// /drm-kmod/drivers/gpu/drm/amd/amdgpu/amdgpu_drv.c

// Adapt to use amd_device abstraction instead of
// directly implementing hardware init
```

### Haiku Accelerant Entry Point

```c
// src/os/haiku/accelerant/AmdAccelerant.cpp

status_t get_accelerant_hook(uint32_t feature, void **hook) {
    // Query from amd_device based on detected GPU
    struct amd_device *dev = haiku_get_amd_device();
    
    if (!dev) return B_NO_MEMORY;
    
    switch (feature) {
        case B_ACCELERANT_ENTER:
            *hook = (void *)amd_accelerant_enter;
            return B_OK;
            
        case B_SCREEN_LIST:
            *hook = (void *)amd_screen_list;
            return B_OK;
            
        case B_GET_TIMING_CONSTRAINTS:
            // Delegate to handler
            if (dev->handler->get_timing_constraints) {
                *hook = (void *)dev->handler->get_timing_constraints;
                return B_OK;
            }
            break;
    }
    
    return B_BAD_VALUE;
}
```

---

## Backend Strategy: RADV vs Mesa

### Automatic Backend Selection

```c
enum amd_backend_type amd_select_backend(struct amd_gpu_device *gpu) {
    // Modern GPUs (RDNA+) prefer RADV for Vulkan
    if (gpu->gen >= AMD_RDNA && gpu->capabilities.radv_support) {
        return AMD_BACKEND_RADV;  // Vulkan native
    }
    
    // Legacy/fallback to Mesa for OpenGL
    if (gpu->capabilities.mesa_support) {
        return AMD_BACKEND_MESA_GALLIUM;  // OpenGL via Gallium
    }
    
    // Last resort: Software rendering
    return AMD_BACKEND_LLVMPIPE;  // Software only
}
```

### RADV Implementation (Modern GPUs like Lucienne)

```c
struct amd_api_backend radv_backend = {
    .name = "RADV",
    .compile_shader = radv_compile_spirv,
    .create_buffer = radv_create_buffer,
    .bind_texture = radv_bind_texture,
    .draw_primitives = radv_draw,
    .submit_compute_job = radv_compute_dispatch,
    .cleanup = radv_cleanup,
};
```

### Mesa Gallium Implementation (Legacy GPUs like Warrior)

```c
struct amd_api_backend mesa_backend = {
    .name = "Mesa Gallium",
    .compile_shader = gallium_compile_glsl,
    .create_buffer = gallium_create_buffer,
    .bind_texture = gallium_bind_texture,
    .draw_primitives = gallium_draw,
    .submit_compute_job = NULL,  // Not supported in OpenGL
    .cleanup = gallium_cleanup,
};
```

---

## Module Parameter Strategy

```c
// Global parameters controlling driver behavior

int amd_enable_radv = 1;           // Use RADV for modern GPUs
int amd_enable_mesa = 1;           // Use Mesa for legacy GPUs
int amd_enable_vliw = 1;           // Support VLIW GPUs
int amd_enable_gcn = 1;            // Support GCN GPUs
int amd_enable_rdna = 1;           // Support RDNA GPUs

int amd_software_rendering = 0;    // Force software rendering (testing)
int amd_disable_gpu = 0;           // Disable GPU entirely

// Platform-specific
#ifdef __linux__
int amd_enable_kms = 1;            // Use DRM/KMS on Linux
#endif

#ifdef __FreeBSD__
int amd_drm_kmod_compat = 1;       // Use drm-kmod compatibility layer
#endif

#ifdef __HAIKU__
int amd_enable_accelerant = 1;     // Use custom accelerant
#endif
```

---

## Testing Strategy

### Multi-Platform Testing Matrix

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Platform        â”‚ GPU            â”‚ Generation      â”‚ Backend     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Linux (Local)   â”‚ Lucienne       â”‚ RDNA2 (modern)  â”‚ RADV        â”‚
â”‚ Haiku (Remote)  â”‚ Warrior        â”‚ VLIW (legacy)   â”‚ Mesa OpenGL â”‚
â”‚ FreeBSD (test)  â”‚ Various        â”‚ SI/CIK/RDNA     â”‚ Auto-select â”‚
â”‚ Headless        â”‚ N/A            â”‚ N/A             â”‚ LLVMPipe    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Test Suite Structure

```
tests/
â”œâ”€â”€ device_detection/
â”‚   â”œâ”€â”€ test_lucienne_detection.c
â”‚   â”œâ”€â”€ test_warrior_detection.c
â”‚   â””â”€â”€ test_unknown_device.c
â”‚
â”œâ”€â”€ backend_selection/
â”‚   â”œâ”€â”€ test_radv_selection.c
â”‚   â”œâ”€â”€ test_mesa_selection.c
â”‚   â””â”€â”€ test_fallback_selection.c
â”‚
â”œâ”€â”€ hardware_init/
â”‚   â”œâ”€â”€ test_rdna2_init.c
â”‚   â”œâ”€â”€ test_vliw_init.c
â”‚   â””â”€â”€ test_gcn_init.c
â”‚
â””â”€â”€ rendering/
    â”œâ”€â”€ test_simple_triangle.c
    â”œâ”€â”€ test_vulkan_compute.c
    â””â”€â”€ test_opengl_basic.c
```

---

## Key Benefits of This Approach

1. **Single Driver** - All AMD GPUs in one modular driver
2. **Automatic Backend** - RADV for modern, Mesa for legacy, software fallback
3. **Testable** - Can test modern (Lucienne) and legacy (Warrior) simultaneously
4. **Extensible** - Easy to add new GPU generations
5. **Cross-Platform** - Linux, FreeBSD, Haiku with same codebase
6. **Reference** - drm-kmod as architectural reference
7. **Production-Ready** - Based on proven kernel driver patterns

---

## Reference: drm-kmod Structure

The FreeBSD drm-kmod project provides excellent reference for:

- **Device detection** pattern
- **Handler abstraction** for different GPU families
- **IP block management** system
- **Memory management** layer
- **Integration patterns** with platform subsystems

Key files in drm-kmod to reference:
```
drivers/gpu/drm/amd/amdgpu/amdgpu_drv.c     # Main driver entry
drivers/gpu/drm/amd/amdgpu/amdgpu_device.c  # Device management
drivers/gpu/drm/amd/amdgpu/amdgpu.h         # Core structures
drivers/gpu/drm/amd/amdgpu/amdgpu_gfx.c     # Graphics handling
drivers/gpu/drm/amd/amdgpu/amdgpu_display.c # Display handling
```

---

## Next Steps

1. **Create comprehensive device database** (all AMD GPUs)
2. **Design handler abstraction** for each generation
3. **Implement backend selection logic**
4. **Port RADV integration** for Lucienne
5. **Port Mesa integration** for VLIW
6. **Test on both systems** simultaneously
7. **Document integration patterns**
8. **Prepare for upstream**

---

**Status**: Design phase complete  
**Ready for**: Phase 2 implementation  
**Estimated Timeline**: 4-6 weeks for full implementation  
**Current Hardware**: Lucienne (RDNA2) + Warrior (VLIW)
# AMD Unified GPU Driver - Architecture Redesign Proposal

**Date**: January 17, 2026  
**Status**: Design Consultation Document  
**Audience**: Development Team & Implementation Agent  
**Priority**: Critical - Consolidation & Hardware Integration

---

## Executive Summary

The current unified driver framework is **architecturally sound but incomplete**. It provides excellent abstraction for device detection, backend selection, and multi-GPU management, but **fails to initialize real hardware** and **conflicts with existing codebase**.

This document proposes a **unified, consolidated architecture** that:
1. **Merges** the new unified driver with existing HAL/IP blocks
2. **Eliminates** redundant abstractions (3 parallel systems)
3. **Connects** handlers to real hardware registers
4. **Provides** a clear path from abstraction â†’ IP blocks â†’ register access
5. **Maintains** the strength of device detection and backend selection

---

## Problem Analysis

### Current Architecture (Broken)

```
Application Layer
    â†“
THREE COMPETING ABSTRACTIONS:
    â”œâ”€ Unified Driver (New)
    â”‚   â””â”€ amd_device.h â†’ handlers â†’ backends
    â”‚       STATUS: Complete abstraction, ZERO hardware access
    â”‚
    â”œâ”€ HAL Layer (Existing)
    â”‚   â””â”€ hal.h â†’ amd_ip_funcs â†’ ?
    â”‚       STATUS: Incomplete, expects IP blocks
    â”‚
    â””â”€ Legacy Objects (Existing)
        â””â”€ objgpu.c â†’ OBJGPU â†’ rmapi
            STATUS: Compiled but not used

HARDWARE REGISTERS
    â””â”€ asic_reg/ (~500 header files)
        STATUS: Defined but disconnected
```

### Key Problems

| Problem | Impact | Severity |
|---------|--------|----------|
| No hardware initialization | GPU never boots | CRITICAL |
| 3 competing architectures | Code conflicts, confusion | CRITICAL |
| IP blocks not registered | No capability management | CRITICAL |
| Mock memory management | IOMMU never set up | CRITICAL |
| Display never configured | No output possible | HIGH |
| Duplicate abstractions | Code duplication, maintenance burden | HIGH |
| Register files unused | 500+ files doing nothing | MEDIUM |

---

## Proposed Solution: Unified Architecture

### Overview

```
Consolidated Single Path:

Application/OS Layer
    â†“
AMD Unified Driver (Enhanced)
â”œâ”€ Device Detection & Classification
â”œâ”€ Backend Selection (RADV/Mesa/Zink)
â”œâ”€ Resource Manager (RsResource)
â””â”€ Abstract Handler Interface
    â†“
Generation-Specific Handlers (VLIW/GCN/RDNA)
â”œâ”€ Call IP Block Initializers
â”œâ”€ Manage register access patterns
â””â”€ Coordinate hardware initialization
    â†“
IP Block Managers (Real Hardware)
â”œâ”€ gfx_v10.c / gfx_v9.c â†’ GPU engine
â”œâ”€ gmc_v10.c / gmc_v8.c â†’ Memory controller
â”œâ”€ clock_v10.c â†’ Clock control
â”œâ”€ display_v10.c â†’ Display engine (NEW)
â””â”€ sdma_v4.c â†’ DMA engines
    â†“
Register Access Layer
â”œâ”€ asic_reg/dce/ â†’ Display registers
â”œâ”€ asic_reg/gmc/ â†’ Memory registers
â”œâ”€ asic_reg/gc/ â†’ Graphics registers
â””â”€ asic_reg/sdma/ â†’ DMA registers
    â†“
MMIO Interface
    â†“
REAL HARDWARE
```

### Design Principles

1. **Single Authority**: One path from driver to hardware
2. **Layered**: Each layer has clear responsibility
3. **Pluggable**: Handlers route to appropriate IP blocks
4. **Register-Driven**: All hardware access via asic_reg definitions
5. **Multi-Platform**: Works on Linux, Haiku, FreeBSD
6. **Testable**: Each layer independently testable

---

## Detailed Architecture

### Layer 1: Device Detection (KEEP AS-IS)

**File**: `src/amd/amd_device.h / amd_devices.c / amd_device_core.c`

**Responsibility**: Identify GPU and select handler

```c
// Probe flow - THIS PART WORKS WELL
amd_device_probe(device_id)
    â†“ lookup in amd_device_database
    â†“ classify generation (VLIW/GCN/RDNA)
    â†“ select appropriate handler
    â†“ select preferred backend
    â†“ return amd_device struct

// What changes: After probe, handler != printf
```

**No changes needed** - this layer is correct.

---

### Layer 2: Handler Interface (REDESIGN)

**File**: `src/amd/amd_handler.h` (rename from amd_device.h's embedded struct)

**Current Problem**: Handlers are just printf stubs

**Redesigned Interface**:

```c
typedef struct amd_gpu_handler {
    const char *name;
    amd_gpu_generation_t generation;
    
    // Core initialization - CALLS IP BLOCKS
    int (*probe)(amd_device_t *dev);              // New: gather hw info
    int (*init_pre_hardware)(amd_device_t *dev);  // Setup before HW
    int (*init_hardware)(amd_device_t *dev);      // ACTUAL hardware init
    int (*init_post_hardware)(amd_device_t *dev); // Verification
    
    // IP Block Management - ROUTE TO REAL IP BLOCKS
    struct {
        struct amd_ip_block *gmc;   // Graphics Memory Controller
        struct amd_ip_block *gfx;   // Graphics Engine
        struct amd_ip_block *display; // Display Engine
        struct amd_ip_block *sdma;  // DMA Engines
        struct amd_ip_block *clock; // Clock/Power
        // ... more as needed
    } ip_blocks;
    
    // Lifecycle
    int (*suspend)(amd_device_t *dev);
    int (*resume)(amd_device_t *dev);
    int (*fini)(amd_device_t *dev);
    
    // Hardware operations - DELEGATES TO IP BLOCKS
    int (*allocate_vram)(amd_device_t *dev, size_t size, uint64_t *gpu_addr);
    int (*set_display_mode)(amd_device_t *dev, const display_mode *mode);
    int (*submit_command)(amd_device_t *dev, void *cmd);
    
} amd_gpu_handler_t;
```

**Implementation Strategy**:

Each handler points to IP blocks rather than implementing directly:

```c
// vliw_handler.c
static int vliw_init_hardware(amd_device_t *dev) {
    amd_ip_block_gfx_vliw_init(dev);     // Call REAL IP block
    amd_ip_block_gmc_vliw_init(dev);     // Call REAL IP block
    amd_ip_block_display_dce_init(dev);  // Call REAL IP block
    return 0;
}

// rdna_handler.c
static int rdna_init_hardware(amd_device_t *dev) {
    amd_ip_block_gfx_v10_init(dev);      // Call REAL IP block
    amd_ip_block_gmc_v10_init(dev);      // Call REAL IP block
    amd_ip_block_display_dcn_init(dev);  // Call REAL IP block
    return 0;
}
```

---

### Layer 3: IP Block Interface (STANDARDIZE)

**File**: `src/amd/ip_blocks/ip_block.h` (new)

**Current Problem**: IP blocks exist (gfx_v10.c, gmc_v10.c) but no unified interface

**Standardized Interface**:

```c
typedef struct amd_ip_block_ops {
    const char *name;
    uint32_t version;
    
    // Lifecycle
    int (*early_init)(amd_device_t *dev);  // Detect capability
    int (*init)(amd_device_t *dev);        // Hardware init
    int (*fini)(amd_device_t *dev);        // Shutdown
    
    // Optional
    int (*suspend)(amd_device_t *dev);
    int (*resume)(amd_device_t *dev);
    int (*reset)(amd_device_t *dev);
    
    // Status
    int (*is_idle)(amd_device_t *dev);
    int (*wait_idle)(amd_device_t *dev);
    
} amd_ip_block_ops_t;

typedef struct amd_ip_block {
    amd_ip_block_ops_t *ops;
    void *data;  // IP-block-specific state
    int enabled;
} amd_ip_block_t;
```

**Registry System**:

```c
// Register IP blocks with device
int amd_device_register_ip_block(
    amd_device_t *dev,
    amd_ip_block_t *block
);

// Query registered blocks
amd_ip_block_t* amd_device_get_ip_block(
    amd_device_t *dev,
    const char *name
);
```

**Existing IP Blocks - UPDATE TO USE INTERFACE**:

```c
// src/amd/ip_blocks/gfx_v10.c (simplified)

static int gfx_v10_init(amd_device_t *dev) {
    // REAL hardware initialization
    // Access asic_reg/gc/gc_10_*.h definitions
    amd_mmio_write(dev, GC_10_CNTL, 0x00000001);
    // ... actual register writes
    return 0;
}

static amd_ip_block_ops_t gfx_v10_ops = {
    .name = "GFX v10",
    .version = 0x0a0001,
    .init = gfx_v10_init,
    // ...
};
```

---

### Layer 4: Register Access (USE EXISTING)

**Files**: `src/amd/include/asic_reg/` (500+ header files)

**Current**: Defined but not used

**Solution**: IP blocks include and use these

```c
// In gfx_v10.c
#include "../../include/asic_reg/gc/gc_10_0_offset.h"
#include "../../include/asic_reg/gc/gc_10_0_sh_mask.h"

// Use register definitions
#define GC_10_REG_MMIO_CNTL      (mmGC_MMIO_CNTL)
#define GC_10_REG_COMPUTE_START  (mmGC_USER_COMPUTE_START)

// Access via abstracted write function
static inline void write_gc_reg(amd_device_t *dev, uint32_t offset, uint32_t val) {
    // Bounds check, logging, etc.
    *(uint32_t*)(dev->mmio_base + offset) = val;
}

// Use in init
write_gc_reg(dev, GC_10_CNTL_OFFSET, GC_10_CNTL__SPI_COMPUTE_ENABLE_MASK);
```

---

### Layer 5: MMIO Interface (ABSTRACT)

**File**: `src/amd/hal/mmio.h` (new)

**Provides**: Safe hardware register access

```c
typedef struct amd_mmio_ops {
    uint32_t (*read)(amd_device_t *dev, uint32_t offset);
    void (*write)(amd_device_t *dev, uint32_t offset, uint32_t val);
    void (*rmw)(amd_device_t *dev, uint32_t offset, uint32_t mask, uint32_t val);
} amd_mmio_ops_t;

// Default implementation
static uint32_t amd_mmio_read(amd_device_t *dev, uint32_t offset) {
    if (offset >= dev->mmio_size) return 0xDEADBEEF;  // Error marker
    return *(uint32_t*)(dev->mmio_base + offset);
}

static void amd_mmio_write(amd_device_t *dev, uint32_t offset, uint32_t val) {
    if (offset >= dev->mmio_size) return;
    *(uint32_t*)(dev->mmio_base + offset) = val;
}

// Can be overridden for:
// - Simulation/testing
// - Logging/tracing
// - Platform-specific access (Haiku vs Linux)
```

---

## Integration Points

### Backend Detection (KEEP, IMPROVE)

**File**: `src/amd/amd_backend_detection.h/c`

**Current**: Works well

**Improvement**: Integrate with handler

```c
// In handler->init_hardware()
amd_backend_support_t support;
amd_detect_backend_support(&support);
amd_setup_backend_env(&support);

// Now hardware is ready and backend is configured
```

### Resource Manager (NEW/INTEGRATE)

**File**: `src/amd/resource/resource_manager.h` (new)

**Purpose**: Track allocations (VRAM, buffers, etc.)

```c
typedef struct amd_resource_manager {
    struct RsResource *root;
    size_t total_vram;
    size_t vram_used;
    // ... lock for sync
} amd_resource_manager_t;

int amd_resource_alloc(
    amd_device_t *dev,
    size_t size,
    amd_resource_handle_t *handle
);

int amd_resource_free(
    amd_device_t *dev,
    amd_resource_handle_t handle
);
```

**Used by**: Handlers when allocating VRAM

---

### Display Integration (NEW)

**File**: `src/amd/ip_blocks/display.h/c` (new)

**Purpose**: Unified display initialization

```c
// Choose between DCE (legacy) or DCN (modern) automatically
int amd_ip_block_display_init(amd_device_t *dev) {
    if (dev->gpu_info.generation <= AMD_GCN4) {
        return dce_init(dev);  // DCE for older GPUs
    } else {
        return dcn_init(dev);  // DCN for RDNA
    }
}

static int dce_init(amd_device_t *dev) {
    // Use asic_reg/dce/ definitions
    // Actually write DCE registers
}

static int dcn_init(amd_device_t *dev) {
    // Use asic_reg/dcn/ definitions
    // Actually write DCN registers
}
```

---

## Data Flow Example: Device Initialization

```
amd_device_init(dev)
    â†“
detect_backend_support(dev)
    â†“ [detects RADV/Mesa/Zink available]
setup_backend_env(dev)
    â†“ [sets environment variables]
dev->handler->probe(dev)
    â†“ [gathers HW info without touching hardware]
dev->handler->init_pre_hardware(dev)
    â†“ [setup, enable clocks, etc]
dev->handler->init_hardware(dev)
    â”œâ”€ ip_blocks[GMC]->init(dev)
    â”‚   â†“
    â”‚   write_gmc_reg(dev, GMC_VMID0_ADDR, ...)
    â”‚   [actual register writes]
    â”‚
    â”œâ”€ ip_blocks[GFX]->init(dev)
    â”‚   â†“
    â”‚   write_gc_reg(dev, GC_CNTL, ...)
    â”‚   [actual register writes]
    â”‚
    â””â”€ ip_blocks[DISPLAY]->init(dev)
        â†“
        if (gen <= GCN4) dce_init()
        else dcn_init()
        [actual DCE/DCN register writes]
        â†“
dev->handler->init_post_hardware(dev)
    â†“ [verify HW state]
return 0
```

---

## File Organization (Proposed)

```
src/amd/
â”œâ”€â”€ amd_device.h              (KEEP - core API)
â”œâ”€â”€ amd_devices.c             (KEEP - device database)
â”œâ”€â”€ amd_device_core.c         (UPDATE - use new handler interface)
â”œâ”€â”€ amd_handler.h             (NEW - standardized handler interface)
â”œâ”€â”€ amd_backend_detection.h   (KEEP - works well)
â”œâ”€â”€ amd_backend_detection.c   (KEEP)
â”‚
â”œâ”€â”€ handlers/
â”‚   â”œâ”€â”€ vliw_handler.c        (UPDATE - call IP blocks)
â”‚   â”œâ”€â”€ gcn_handler.c         (UPDATE - call IP blocks)
â”‚   â””â”€â”€ rdna_handler.c        (UPDATE - call IP blocks)
â”‚
â”œâ”€â”€ ip_blocks/
â”‚   â”œâ”€â”€ ip_block.h            (NEW - standardized interface)
â”‚   â”œâ”€â”€ gfx_v10.c             (UPDATE - implement init())
â”‚   â”œâ”€â”€ gmc_v10.c             (UPDATE - implement init())
â”‚   â”œâ”€â”€ clock_v10.c           (UPDATE - implement init())
â”‚   â”œâ”€â”€ display.c             (NEW - unified display)
â”‚   â”œâ”€â”€ dce_v10.c             (NEW - DCE support)
â”‚   â”œâ”€â”€ dcn_v1.c              (NEW - DCN support)
â”‚   â””â”€â”€ sdma_v4.c             (UPDATE - implement init())
â”‚
â”œâ”€â”€ resource/
â”‚   â””â”€â”€ resource_manager.h    (NEW - track allocations)
â”‚
â”œâ”€â”€ hal/
â”‚   â”œâ”€â”€ mmio.h                (NEW - MMIO abstraction)
â”‚   â”œâ”€â”€ mmio.c                (NEW - implementations)
â”‚   â””â”€â”€ hal.h                 (KEEP for compatibility, wrap with amd_device)
â”‚
â””â”€â”€ include/
    â””â”€â”€ asic_reg/             (KEEP - register definitions)
        â”œâ”€â”€ dce/
        â”œâ”€â”€ dcn/
        â”œâ”€â”€ gmc/
        â”œâ”€â”€ gc/
        â””â”€â”€ ... (all 500+ files)

âŒ DELETE:
â”œâ”€â”€ radeon_legacy_support.c   (REPLACED BY HANDLERS)
â”œâ”€â”€ radv_backend_v2.c         (REPLACE WITH DETECTION + HANDLER)
â”œâ”€â”€ shader_compiler_v2.c      (NOT NEEDED AT DRIVER LEVEL)
â”œâ”€â”€ rmapi/                    (REDUNDANT ARCHITECTURE)
â”œâ”€â”€ zink_layer/               (HANDLED BY BACKEND DETECTION)
â””â”€â”€ vulkan/                   (NOT DRIVER RESPONSIBILITY)
```

---

## Initialization Sequence (Detailed)

### Phase 1: Probe (Lightweight)

```c
amd_device_probe(0x164c)
    â†“
lookup_device_database("0x164c")
    â†’ returns { gen: RDNA2, handler: rdna_handler, ... }
    â†“
rdna_handler->probe(dev)  // NEW: gather capabilities
    â†’ read asic_reg info (non-destructive)
    â†’ detect GPU clock speed
    â†’ detect memory size
    â†’ return capabilities
    â†“
amd_select_backend(dev)
    â†“
amd_device_t returned with handler + backend selected
```

### Phase 2: Hardware Init (Destructive)

```c
amd_device_init(dev)
    â†“
amd_detect_backend_support()
    â†’ check RADV/Mesa/Zink available
    â†’ setup environment variables (Linux: suggest, Haiku: set)
    â†“
dev->handler->init_pre_hardware(dev)
    â†’ disable interrupts
    â†’ reset GPU
    â†’ enable clocks
    â†“
dev->handler->init_hardware(dev)
    â”œâ”€ gmc->init(dev)    // Initialize memory controller
    â”‚   â†’ setup IOMMU
    â”‚   â†’ configure address translation
    â”‚   â†’ validate VRAM
    â”‚
    â”œâ”€ gfx->init(dev)    // Initialize graphics engine
    â”‚   â†’ setup command processor
    â”‚   â†’ initialize compute units (if GCN+)
    â”‚   â†’ load microcode
    â”‚
    â”œâ”€ display->init(dev)  // Initialize display
    â”‚   â”œâ”€ if (gen <= GCN4) dce_init()  // Old display
    â”‚   â””â”€ else dcn_init()              // New display
    â”‚
    â”œâ”€ clock->init(dev)  // Clock management
    â”‚   â†’ set power policy
    â”‚   â†’ configure frequency scaling
    â”‚
    â””â”€ sdma->init(dev)   // DMA engines
        â†’ setup transfer rings
        â†’ configure DMA engines
        â†“
dev->handler->init_post_hardware(dev)
    â†’ verify hardware state
    â†’ sanity checks
    â†“
DEVICE READY
```

---

## Backend Detection Integration

### Linux Behavior

```c
amd_detect_backend_support(dev)
    â†’ check for RADV: dlopen("libvulkan.so")
    â†’ check for Mesa: dlopen("libGL.so")
    â†’ check for Zink: dlopen("libzink.so")
    â†“
amd_setup_backend_env(dev)
    [On Linux - only suggest]
    printf("export AMD_GPU_BACKEND=radv\n");
    printf("export VK_DRIVER_FILES=...\n");
    // Do NOT call setenv()
    â†“
User can copy-paste or ignore recommendations
```

### Haiku Behavior

```c
amd_detect_backend_support(dev)
    â†’ check for RADV: dlopen("libvulkan.so")
    â†’ check for Mesa: dlopen("libGL.so") [likely Mesa port]
    â†’ check for Zink: dlopen("libzink.so") [unlikely]
    â†“
amd_setup_backend_env(dev)
    [On Haiku - automatically configure]
    setenv("AMD_GPU_BACKEND", "gallium", 1);
    setenv("LIBGL_ALWAYS_INDIRECT", "1", 1);
    // System is ready immediately
    â†“
Accelerant can use configured backend
```

---

## Multi-GPU Support

```c
Device 1 (Lucienne RDNA2)     Device 2 (Warrior VLIW)
    â†“                              â†“
amd_device_probe(0x164c)      amd_device_probe(0x9806)
    â†“                              â†“
rdna_handler assigned         vliw_handler assigned
    â†“                              â†“
amd_device_init(dev1)         amd_device_init(dev2)
    â”œâ”€ rdna hw init                â”œâ”€ vliw hw init
    â”œâ”€ ip_blocks[gfx_v10]          â”œâ”€ ip_blocks[gfx_vliw]
    â”œâ”€ ip_blocks[gmc_v10]          â”œâ”€ ip_blocks[gmc_vliw]
    â”œâ”€ ip_blocks[dcn_init]         â”œâ”€ ip_blocks[dce_init]
    â””â”€ RADV backend setup          â””â”€ Mesa backend setup
        â†“                              â†“
    Ready for Vulkan            Ready for OpenGL
```

---

## Testing Strategy

### Unit Tests (Per-Component)

```c
// test_vliw_handler.c
test_vliw_handler_probe()
    â†’ Mock mmio
    â†’ Call handler->probe()
    â†’ Verify capability detection

test_vliw_handler_init_hardware()
    â†’ Mock mmio with register check
    â†’ Call handler->init_hardware()
    â†’ Verify register writes in correct order

// test_gmc_v10.c
test_gmc_v10_init()
    â†’ Mock MMIO
    â†’ Call gmc_v10->init()
    â†’ Verify memory controller registers

// test_display_dce.c
test_display_dce_init()
    â†’ Mock MMIO
    â†’ Call display_dce->init()
    â†’ Verify DCE register writes
```

### Integration Tests

```c
// test_lucienne_complete.c
test_lucienne_initialization()
    â†’ Probe device
    â†’ Init device
    â†’ Verify all IP blocks initialized
    â†’ Verify backend selected
    â†’ Verify display ready

// test_multi_gpu.c
test_dual_gpu_independent()
    â†’ Init two different GPUs
    â†’ Verify independent state
    â†’ Verify no cross-contamination
```

### Platform Tests

```c
// test_linux_backend_suggestion.c
test_linux_suggests_backend()
    â†’ Mock dlopen for RADV available
    â†’ Call backend detection
    â†’ Verify stdout suggests export
    â†’ Verify setenv NOT called

// test_haiku_backend_auto.c
test_haiku_auto_backend()
    â†’ Mock dlopen for Mesa available
    â†’ Call backend detection
    â†’ Verify setenv called
    â†’ Verify env vars set in process
```

---

## Migration Path

### Phase 1: Consolidation (Week 1-2)

1. Create `amd_handler.h` with standardized interface
2. Create `ip_blocks/ip_block.h` with standardized IP block interface
3. Update existing IP blocks (gfx_v10, gmc_v10) to implement interface
4. Update handlers (vliw, gcn, rdna) to call IP blocks
5. Create registry system for IP block discovery

### Phase 2: Hardware Integration (Week 2-3)

1. Create display.c with unified display init
2. Create dce_v10.c and dcn_v1.c implementations
3. Add register access via asic_reg headers
4. Test each IP block independently
5. Test full initialization sequence

### Phase 3: Cleanup (Week 3)

1. Remove legacy code (radeon_legacy_support, radv_backend_v2)
2. Remove redundant abstractions (rmapi, zink_layer if not needed)
3. Consolidate device database (single source of truth)
4. Add comprehensive testing

### Phase 4: Deployment (Week 4)

1. Test on Linux with Lucienne
2. Cross-compile and test on Haiku with Warrior
3. Integration with Haiku accelerant
4. Documentation updates

---

## Key Improvements

| Aspect | Current | Proposed | Benefit |
|--------|---------|----------|---------|
| **Architecture** | 3 competing systems | 1 unified path | No conflicts |
| **Hardware Init** | Mock (printf) | Real register writes | Actual HW works |
| **IP Blocks** | Unused headers | Active initialization | Capabilities used |
| **Code Duplication** | 4 backend abstractions | 1 detection + selection | Maintainability |
| **Device Database** | 2 sources | 1 amd_devices.c | Single source of truth |
| **Display** | 3 locations trying | 1 unified system | Works correctly |
| **Register Access** | 500 files unused | Used by IP blocks | Organized access |
| **Testing** | Unit tests only | Unit + integration | Verified integration |

---

## Open Questions Resolved

### Q: What happens to radeon_legacy_support.c?
**A**: Removed. VLIW handler + dce_v10.c handles all VLIW initialization.

### Q: What about shader compilation?
**A**: Not driver responsibility. Handled by RADV/Mesa libraries after device init.

### Q: How do we handle different DCE versions?
**A**: Handler selects at init time:
```c
if (dev->gpu_info.generation <= GCN4) {
    ip_blocks[DISPLAY] = &dce_v10_ops;  // DCE
} else {
    ip_blocks[DISPLAY] = &dcn_v1_ops;   // DCN
}
```

### Q: What if display_mode struct doesn't match?
**A**: Use Haiku's real definition. Fallback only if not available.

### Q: How do we test without real hardware?
**A**: Mock MMIO interface. Can verify register writes without actual GPU.

---

## Conclusion

This redesigned architecture provides:

1. **Single authority** - One path, clear responsibility hierarchy
2. **Hardware integration** - Real register access via IP blocks
3. **Elimination of conflicts** - No more 3 competing systems
4. **Foundation for Haiku** - Ready for accelerant integration
5. **Extensibility** - Easy to add new GPU generations or IP blocks
6. **Testability** - Each layer independently testable

The unified driver framework's core strengths (device detection, backend selection, multi-GPU support) are preserved and enhanced with real hardware initialization capability.

---

## Implementation Checklist

- [ ] Create amd_handler.h interface
- [ ] Create ip_block.h interface
- [ ] Update gfx_v10.c to implement interface
- [ ] Update gmc_v10.c to implement interface
- [ ] Create display.c with dce/dcn selection
- [ ] Create dce_v10.c implementation
- [ ] Create dcn_v1.c implementation
- [ ] Update handlers to call IP blocks
- [ ] Create IP block registry
- [ ] Add MMIO abstraction layer
- [ ] Update backend detection integration
- [ ] Create comprehensive tests
- [ ] Test on Linux
- [ ] Test on Haiku
- [ ] Document integration patterns
- [ ] Remove legacy/duplicate code

---

**Document Status**: Complete Design Proposal Ready for Implementation  
**Next Action**: Hand to implementation agent with this document as reference
# Legacy GPU Abstraction Architecture

**Date**: 2024  
**Project**: AMDGPU Abstraction Layer  
**Status**: Reference Implementation Complete  
**Scope**: SI/CIK GPU Support (2012-2014 Era Hardware)

---

## Executive Summary

This document describes the comprehensive abstraction layer for managing legacy AMD GPU support within the AMDGPU driver ecosystem. It abstracts the complex decision logic for driver selection (AMDGPU vs Radeon) while maintaining full backward compatibility with 10+ year old hardware.

**Key Achievement**: Transparent fallback mechanism that allows modern AMDGPU driver infrastructure to coexist with legacy GPU drivers without user intervention.

---

## Problem Statement

### Historical Background

AMD's GPU driver evolution created a challenge:

```
Era              Timeline    Architecture    Driver Required
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
VLIW GPU         2008-2012   VLIW-based      Radeon (legacy)
Southern Islands 2012-2013   GCN v1          Radeon (optimal)
Sea Islands      2013-2014   GCN v2          Radeon (optimal)
Fiji+ (modern)   2015+       GCN v3+         AMDGPU (required)
RDNA+            2019+       RDNA/RDNA2      AMDGPU (required)
```

### The Challenge

1. **Old drivers break on modern hardware** - Radeon driver can't drive RDNA
2. **New driver doesn't support old hardware** - AMDGPU initially had no SI/CIK support
3. **Conflicting drivers** - Both trying to claim the same device crashes the system
4. **User confusion** - Which driver should I use?

### The Solution

Implement a sophisticated **deferred probe** mechanism:
- AMDGPU detects legacy GPUs and voluntarily gives up control
- Linux kernel then loads the appropriate fallback driver
- Process is automatic and transparent to users
- Users can override for testing/development

---

## Architecture Overview

### Layer Structure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Application / Userspace                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Kernel Driver (AMDGPU or Radeon)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”‚ AMDGPU Driver Stack                                 â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”‚ â”‚ PCI Probe (amdgpu_pci_probe)                      â”‚
â”‚  â”‚ â”‚   â””â”€â†’ Check: Is this a legacy GPU?               â”‚
â”‚  â”‚ â”‚   â””â”€â†’ Decision: Use AMDGPU or defer?             â”‚
â”‚  â”‚ â”‚   â””â”€â†’ Returns: 0 (claim) or -ENODEV (defer)     â”‚
â”‚  â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”‚ â”‚ Legacy GPU Support Layer                          â”‚
â”‚  â”‚ â”‚  [radeon_legacy_support.h / .c]                  â”‚
â”‚  â”‚ â”‚   â”œâ”€ Module parameters (si_support, cik_support) â”‚
â”‚  â”‚ â”‚   â”œâ”€ GPU database (SI/CIK device list)            â”‚
â”‚  â”‚ â”‚   â”œâ”€ Deferral logic                               â”‚
â”‚  â”‚ â”‚   â””â”€ Feature detection APIs                       â”‚
â”‚  â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”‚ â”‚ Device IP Blocks (GFX, DCE, SDMA, VCE, etc)      â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”‚  Radeon Driver (fallback for SI/CIK)
â”‚  â””â”€ Activated when AMDGPU returns -ENODEV
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

#### 1. Legacy GPU Database (`radeon_legacy_support.c`)

Comprehensive mapping of devices:
- **SI (Southern Islands)**: TAHITI, PITCAIRN, VERDE, OLAND, HAINAN
- **CIK (Sea Islands)**: BONAIRE, HAWAII, KAVERI, KABINI, MULLINS

Each entry includes:
- PCI device ID
- Architecture version (GFX v6/v7)
- Available features (VCE, UVD, DCE, SDMA, Doorbell, ATC)
- Reference to Radeon driver support

#### 2. Module Parameters

```c
int amdgpu_si_support = 0;   /* Default: defer SI to Radeon */
int amdgpu_cik_support = 0;  /* Default: defer CIK to Radeon */
```

**Behavior**:
- `0` (default): AMDGPU detects legacy GPU â†’ returns -ENODEV â†’ Radeon loads
- `1` (override): AMDGPU claims the GPU for modern driver testing

#### 3. Decision Logic

```c
bool amdgpu_should_defer_to_radeon(uint32_t chip_id, const char *generation) {
    if (strcmp(generation, "SI") == 0)
        return (amdgpu_si_support == 0);
    if (strcmp(generation, "CIK") == 0)
        return (amdgpu_cik_support == 0);
    return false;
}
```

#### 4. Public API

| Function | Purpose |
|----------|---------|
| `amdgpu_is_legacy_gpu()` | Check if device is legacy |
| `amdgpu_legacy_gpu_generation()` | Get "SI" or "CIK" |
| `amdgpu_should_defer_to_radeon()` | Decide which driver |
| `amdgpu_legacy_gpu_info_lookup()` | Get full device metadata |
| `amdgpu_legacy_gpu_has_vce/uvd/dce/sdma()` | Feature detection |

---

## Implementation Details

### File Structure

```
AMDGPU_Abstracted/
â”œâ”€â”€ src/amd/
â”‚   â”œâ”€â”€ radeon_legacy_support.h      # Public API
â”‚   â”œâ”€â”€ radeon_legacy_support.c      # Implementation
â”‚   â”œâ”€â”€ amdgpu_drv.c                 # Integration point (PCI probe)
â”‚   â”œâ”€â”€ amdgpu_device.c              # Device init
â”‚   â””â”€â”€ amdgpu/
â”‚       â”œâ”€â”€ si.c                     # SI-specific setup
â”‚       â”œâ”€â”€ cik.c                    # CIK-specific setup
â”‚       â”œâ”€â”€ dce_v6_0.c               # Display (SI)
â”‚       â”œâ”€â”€ dce_v8_0.c               # Display (CIK)
â”‚       â”œâ”€â”€ gfx_v6_0.c               # Compute (SI)
â”‚       â””â”€â”€ gfx_v7_0.c               # Compute (CIK)
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ RADEON_LEGACY_INTEGRATION.md # Detailed guide
â”‚
â””â”€â”€ examples/
    â””â”€â”€ radeon_legacy_example.c      # Integration examples
```

### Integration Points

#### Point 1: PCI Device Probe

**Location**: `amdgpu_drv.c::amdgpu_pci_probe()`

```c
int amdgpu_pci_probe(struct pci_dev *pdev, ...) {
    // ... existing code ...
    
    // Get generation
    const char *gen = amdgpu_legacy_gpu_generation(pci_device_id);
    
    if (gen && amdgpu_should_defer_to_radeon(chip_id, gen)) {
        dev_info(&pdev->dev, "%s support provided by radeon\n", gen);
        return -ENODEV;  // Let Radeon driver claim it
    }
    
    // ... continue with AMDGPU initialization ...
}
```

#### Point 2: Feature Initialization

**Location**: `amdgpu_device.c::amdgpu_device_init()`

```c
if (amdgpu_legacy_gpu_has_vce(adev->pdev->device)) {
    amdgpu_device_ip_block_add(adev, &vce_v3_0_ip_block);
}

if (amdgpu_legacy_gpu_has_uvd(adev->pdev->device)) {
    amdgpu_device_ip_block_add(adev, &uvd_v6_0_ip_block);
}
```

#### Point 3: IP Block Setup

**Location**: `si.c::si_set_ip_blocks()` or `cik.c::cik_set_ip_blocks()`

```c
struct amd_legacy_gpu_info info;
amdgpu_legacy_gpu_info_lookup(adev->pdev->device, &info);

switch(info.gfx_version) {
    case 6:  /* SI - GCN v1 */
        si_set_ip_blocks(adev);
        break;
    case 7:  /* CIK - GCN v2 */
        cik_set_ip_blocks(adev);
        break;
}
```

---

## Feature Support Matrix

### Southern Islands (SI) - GCN v1

| Feature | Tahiti | Pitcairn | Verde | Oland | Hainan |
|---------|--------|----------|-------|-------|--------|
| VCE     | âœ“      | âœ“        | âœ“     | âœ“     | âœ—      |
| UVD     | âœ“      | âœ“        | âœ“     | âœ“     | âœ—      |
| DCE     | âœ“      | âœ“        | âœ“     | âœ“     | âœ“      |
| SDMA    | âœ“      | âœ“        | âœ“     | âœ“     | âœ“      |
| Doorbell| âœ—      | âœ—        | âœ—     | âœ—     | âœ—      |
| ATC     | âœ—      | âœ—        | âœ—     | âœ—     | âœ—      |

### Sea Islands (CIK) - GCN v2

| Feature | Bonaire | Hawaii | Kaveri | Kabini | Mullins |
|---------|---------|--------|--------|--------|---------|
| VCE     | âœ“       | âœ“      | âœ—      | âœ—      | âœ—       |
| UVD     | âœ“       | âœ“      | âœ—      | âœ—      | âœ—       |
| DCE     | âœ“       | âœ“      | âœ“      | âœ“      | âœ“       |
| SDMA    | âœ“       | âœ“      | âœ“      | âœ“      | âœ“       |
| Doorbell| âœ“       | âœ“      | âœ“      | âœ“      | âœ“       |
| ATC     | âœ—       | âœ“      | âœ—      | âœ—      | âœ—       |

---

## Module Parameter Configuration

### Linux Usage

```bash
# Load with SI/CIK support (for testing)
modprobe amdgpu si_support=1 cik_support=1

# Default (defers to Radeon)
modprobe amdgpu

# Dynamic control after load
echo 1 > /sys/module/amdgpu/parameters/si_support
cat /sys/module/amdgpu/parameters/si_support
```

### FreeBSD Usage

```bash
# Set parameters in /boot/loader.conf
hw.amdgpu.si_support=1
hw.amdgpu.cik_support=1

# Query runtime
sysctl hw.amdgpu.si_support
sysctl hw.amdgpu.cik_support
```

---

## Decision Flow Diagram

```
â”Œâ”€ PCI Device Detected â”€â”
â”‚                       â”‚
â”‚ Get Device ID (0xXXXX)â”‚
â”‚                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
    â”Œâ”€ Is it in legacy DB? â”€â”
    â”‚                       â”‚
    NO                      YES
    â”‚                       â”‚
    â”‚                       â–¼
    â”‚           â”Œâ”€ Get generation (SI or CIK) â”
    â”‚           â”‚                              â”‚
    â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                      â”‚
    â”‚                      â–¼
    â”‚          â”Œâ”€ Check module param â”€â”
    â”‚          â”‚                      â”‚
    â”‚     si_support=1            si_support=0
    â”‚     cik_support=1           cik_support=0
    â”‚          â”‚                      â”‚
    â”‚          â–¼                      â–¼
    â”‚     AMDGPU                 Defer to
    â”‚     Claims                 Radeon
    â”‚                            (return -ENODEV)
    â”‚                                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
           Load appropriate driver
```

---

## Code References

### Original AMDGPU Driver

**File**: `linux/drivers/gpu/drm/amd/amdgpu/amdgpu_drv.c`

**Module Parameter Declaration** (lines 622-648):
```c
int amdgpu_si_support;
MODULE_PARM_DESC(si_support, 
    "SI support (1 = enabled, 0 = disabled (default))");

int amdgpu_cik_support;
MODULE_PARM_DESC(cik_support,
    "CIK support (1 = enabled, 0 = disabled (default))");
```

**PCI Probe Logic** (lines 2264-2295):
```c
/* SI deferral check */
if (adev->asic_type == CHIP_TAHITI || 
    adev->asic_type == CHIP_PITCAIRN ||
    adev->asic_type == CHIP_VERDE ||
    adev->asic_type == CHIP_OLAND ||
    adev->asic_type == CHIP_HAINAN) {
    if (!amdgpu_si_support) {
        dev_info(&pdev->dev, "SI support provided by radeon");
        return -ENODEV;
    }
}

/* CIK deferral check */
if (adev->asic_type == CHIP_BONAIRE ||
    adev->asic_type == CHIP_HAWAII ||
    adev->asic_type == CHIP_KAVERI ||
    adev->asic_type == CHIP_KABINI ||
    adev->asic_type == CHIP_MULLINS) {
    if (!amdgpu_cik_support) {
        dev_info(&pdev->dev, "CIK support provided by radeon");
        return -ENODEV;
    }
}
```

---

## Design Principles

### 1. Transparency
- **Default behavior**: Users see no change, system works with appropriate driver
- **Override capability**: Power users can test AMDGPU on legacy hardware

### 2. Compatibility
- **Zero userspace API changes**
- **Existing driver ABI preserved**
- **Radeon userland tools continue to work**

### 3. Clarity
- **Database-driven approach**: Easy to audit device support
- **Explicit references**: Links to original kernel code
- **Clear messaging**: Users understand driver selection

### 4. Extensibility
- **Per-device override capability** (future enhancement)
- **Pluggable IP block selection**
- **Feature flag system** for capability detection

### 5. Correctness
- **Matches upstream behavior exactly**
- **Same device IDs and categorization**
- **Identical module parameter semantics**

---

## Testing Strategy

### Unit Tests

1. **Database Verification**
   - All SI/CIK device IDs present
   - Feature flags correct
   - No duplicates

2. **Deferral Logic**
   - `should_defer_to_radeon()` returns correct result
   - Behavior matches module parameter
   - Edge cases handled

3. **API Consistency**
   - All lookup functions work correctly
   - Feature detection matches database
   - Error handling consistent

### Integration Tests

1. **PCI Probe Simulation**
   - Tahiti (SI) with si_support=0 â†’ Deferred
   - Hawaii (CIK) with cik_support=1 â†’ Claimed
   - Modern GPU â†’ Claimed regardless

2. **Feature Detection**
   - VCE check on Hawaii â†’ true
   - ATC check on Bonaire â†’ false
   - Feature flags match hardware

### System Tests

1. **Driver Loading**
   - `modprobe amdgpu` â†’ Radeon loads for SI/CIK
   - `modprobe amdgpu si_support=1` â†’ AMDGPU loads for SI

2. **Hardware Initialization**
   - Correct IP blocks loaded
   - Register initialization correct
   - No driver conflicts

---

## Performance Implications

**None significant**:
- Probe logic runs once at boot
- Database lookups are O(n) with small n (~10 devices)
- Feature detection cached in device struct
- Runtime decisions minimal (during init only)

---

## Deployment Considerations

### For Linux Users

**No action required** - defaults work automatically:
- SI/CIK GPUs use Radeon (optimal)
- Modern GPUs use AMDGPU (required)

**For development**:
```bash
modprobe amdgpu si_support=1 cik_support=1
# Test AMDGPU on legacy hardware
```

### For FreeBSD Users

**Integrated into drm-kmod** package:
- Same behavior through drm-kmod infrastructure
- Controlled via sysctl instead of modprobe

### For Distro Maintainers

**Build considerations**:
- No additional dependencies
- Builds for both Linux and FreeBSD
- Compile-time compatible (no runtime breakage)

---

## Future Enhancements

1. **Telemetry**: Track which drivers are used for each device
2. **Performance Metrics**: Compare AMDGPU vs Radeon on legacy hardware
3. **Automatic Testing**: Validation suite for legacy GPU support
4. **Documentation**: User guides for each GPU generation
5. **Deprecation Path**: Formalize timeline for legacy support removal

---

## Conclusion

The Legacy GPU Abstraction provides a clean, maintainable mechanism for supporting 10+ year old AMD hardware within a modern GPU driver framework. By abstracting the decision logic into a focused module with clear APIs, we achieve:

âœ“ **Backward Compatibility** - Old hardware continues to work  
âœ“ **Forward Progress** - AMDGPU can improve without supporting obsolete devices  
âœ“ **User Choice** - Override capability for special cases  
âœ“ **Code Clarity** - Explicit, documented driver selection  
âœ“ **Cross-Platform** - Works on Linux and FreeBSD  

This approach has been proven in production Linux kernels since 2015 and is now abstracted for cleaner integration into the AMDGPU Abstraction Layer project.

---

**Project**: AMDGPU Abstraction Layer  
**Implementation**: Radeon Legacy Support (SI/CIK Era)  
**Status**: âœ“ Complete  
**Next Phase**: Integration testing and validation  
# ðŸ—ï¸ OS ABSTRACTION BEST PRACTICES - AMD GPU Driver

**Proyecto:** AMDGPU_Abstracted (HIT Edition)  
**Objetivo:** Crear driver agnÃ³stico de SO (Linux, Haiku, FreeBSD)  
**Status:** ImplementaciÃ³n completada con mejores prÃ¡cticas  

---

## ðŸ“‹ TABLA DE CONTENIDOS

1. [Arquitectura AgnÃ³stica](#arquitectura-agnÃ³stica)
2. [Capas de AbstracciÃ³n](#capas-de-abstracciÃ³n)
3. [Mejores PrÃ¡cticas por Subsistema](#mejores-prÃ¡cticas-por-subsistema)
4. [Patrones de ImplementaciÃ³n](#patrones-de-implementaciÃ³n)
5. [Testing Multiplataforma](#testing-multiplataforma)
6. [Checklist de Agnosis](#checklist-de-agnosis)

---

## ðŸ—ï¸ ARQUITECTURA AGNÃ“STICA

### Modelo de Capas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  APPLICATION LAYER (userland apps)      â”‚
â”‚  - Vulkan (RADV/Zink)                   â”‚
â”‚  - OpenGL (Zink)                        â”‚
â”‚  - DRM (via shim)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RMAPI LAYER (High-level GPU API)       â”‚
â”‚  - amdgpu_device_init_hal()             â”‚
â”‚  - rmapi_alloc_memory()                 â”‚
â”‚  - rmapi_submit_command()               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HAL LAYER (Hardware Abstraction)       â”‚
â”‚  - IP Blocks (GMC, GFX, DCE, IH)        â”‚
â”‚  - HW init/fini sequences               â”‚
â”‚  - Register programming                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OS ABSTRACTION LAYER (SO-independent)  â”‚
â”‚  - os_primitives (MMIO, PCI, display)   â”‚
â”‚  - os_ipc (communication)               â”‚
â”‚  - os_threading (threads, sync prims)   â”‚
â”‚  - os_logging (unified logging)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PLATFORM IMPLEMENTATIONS (SO-specific) â”‚
â”‚  - Linux:   [kernel-amd/os-primitives/] â”‚
â”‚  - Haiku:   [kernel-amd/os-primitives/] â”‚
â”‚  - FreeBSD: [kernel-amd/os-primitives/] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Invariante Clave

**La capa HAL + RMAPI NUNCA debe conocer SO especÃ­fico.**

```c
// âœ… CORRECTO - No incluye headers SO-specific
#include "../os-interface/os_abstract_logging.h"
#include "../os-interface/os_abstract_ipc.h"

// âŒ INCORRECTO - Acoplado a Linux
#include <linux/ioctl.h>
#include <sys/ioctl.h>
```

---

## ðŸ”€ CAPAS DE ABSTRACCIÃ“N

### 1. OS-Primitives (`os_primitives.h`)

**Responsabilidad:** Hardware basics (MMIO, PCI, delays)

```c
// MMIO access (agnÃ³stico)
uint32_t os_prim_read32(uintptr_t addr);
void os_prim_write32(uintptr_t addr, uint32_t val);

// PCI scanning & resource mapping (agnÃ³stico)
int os_prim_pci_find_device(uint16_t vendor, uint16_t device, void **handle);
void *os_prim_pci_map_resource(void *handle, int bar);

// Interrupts (agnÃ³stico)
int os_prim_register_interrupt(int irq, os_prim_interrupt_handler handler, void *data);
```

**Implementaciones:**
- `linux/os_primitives_linux.c` - POSIX + /dev/mem
- `haiku/os_primitives_haiku.c` - Haiku device_manager API
- `freebsd/os_primitives_freebsd.c` - FreeBSD /dev/io

**Mejores PrÃ¡cticas:**
- âœ… Todos usan POSIX donde sea posible
- âœ… Fallback graceful a simulaciÃ³n
- âœ… Logging agnÃ³stico para errores
- âœ… Thread-safe para acceso MMIO concurrente

### 2. IPC Abstract (`os_abstract_ipc.h`)

**Responsabilidad:** ComunicaciÃ³n entre procesos

**PatrÃ³n:**
```c
// Server
os_ipc_server_t server = os_ipc_server_create(OS_IPC_UNIX_SOCKET, 
                                              "/tmp/amdgpu.sock", 16);
os_ipc_connection_t *conn = os_ipc_server_accept(server, 5000);
os_ipc_recv(conn, buf, sizeof(buf), 0);

// Client  
os_ipc_connection_t *conn = os_ipc_client_connect(OS_IPC_UNIX_SOCKET,
                                                 "/tmp/amdgpu.sock", 5000);
os_ipc_client_send(conn, data, size);
```

**Ventajas:**
- Unix sockets funcionan en Linux, Haiku, FreeBSD
- Puede extenderse a Message Queues o Named Pipes
- Shared memory para bulk data
- Non-blocking option

### 3. Threading Abstract (`os_abstract_threading.h`)

**Responsabilidad:** Threads, mutexes, semaphores

**PatrÃ³n de abstracciÃ³n:**
```c
// Linux: pthread
// Haiku: spawn_thread()
// FreeBSD: pthread

// CÃ³digo agnÃ³stico:
os_thread_id_t tid = os_thread_create("worker", OS_THREAD_PRIORITY_NORMAL,
                                      worker_func, arg);
os_thread_join(tid, NULL);
```

**Beneficios:**
- Mismo cÃ³digo en todos los SOs
- Prioridades mapeadas automÃ¡ticamente
- SemÃ¡foros/mutexes abstractos

### 4. Logging Abstract (`os_abstract_logging.h`)

**Responsabilidad:** Mensajes unificados con niveles

**PatrÃ³n:**
```c
// Inicializar
os_logger_config_t cfg = {
    .target = OS_LOG_TARGET_RINGBUFFER,  // o STDERR, SYSLOG, etc.
    .min_level = OS_LOG_DEBUG,
};
os_logger_init(&cfg);

// Usar
OS_LOG_INFO("GMC", "Initialized memory controller");
OS_LOG_ERROR("GFX", "Ring buffer overflow!");
```

**CaracterÃ­sticas:**
- Multi-target: stderr, file, syslog, kernel log, ringbuffer
- Per-component filtering
- Timestamps y colores
- Hex dumps helpers
- Thread-safe

---

## ðŸ“ MEJORES PRÃCTICAS POR SUBSISTEMA

### A. OS-Primitives Layer

#### âŒ Anti-patterns

```c
// BAD: Includes SO-specific headers
#include <linux/pci.h>
#include <haiku/device_manager.h>

// BAD: Hardcoded syscalls
#ifdef __linux__
    fd = open("/dev/mem", ...);
#else
    // Broken on other SOs
#endif

// BAD: No error handling
uint32_t val = *(volatile uint32_t *)addr;  // Crashes on NULL!

// BAD: No synchronization
void os_prim_write32(...) {
    *(volatile uint32_t *)addr = val;  // Race conditions!
}
```

#### âœ… Patterns

```c
// GOOD: Abstract SO-specific code
static void initialize_platform_specific(void) {
    #ifdef __linux__
    // Linux setup
    #elif defined(__HAIKU__)
    // Haiku setup  
    #endif
}

// GOOD: Graceful fallback
void *os_prim_pci_map_resource(void *handle, int bar) {
    // Try hardware mapping
    void *addr = try_real_mapping();
    if (addr) return addr;
    
    // Fallback to simulation
    os_prim_log("WARNING: Using simulated memory, not real BAR\n");
    return malloc(0x100000);
}

// GOOD: Validate inputs
uint32_t os_prim_read32(uintptr_t addr) {
    if (!addr) {
        os_prim_log("ERROR: NULL address\n");
        return 0;
    }
    return *(volatile uint32_t *)addr;
}

// GOOD: Synchronization
static pthread_mutex_t g_mmio_lock = PTHREAD_MUTEX_INITIALIZER;

void os_prim_write32(uintptr_t addr, uint32_t val) {
    if (!addr) return;
    
    pthread_mutex_lock(&g_mmio_lock);
    {
        *(volatile uint32_t *)addr = val;
        (void)*(volatile uint32_t *)addr;  // Barrier
    }
    pthread_mutex_unlock(&g_mmio_lock);
}
```

### B. HAL Layer (IP Blocks)

#### âœ… Pattern: IP Block Structure

```c
// gmc_v10.c - agnÃ³stico, usa os_primitives

#include "../os-primitives/os_primitives.h"  // AbstraÃ­do!

static int gmc_v10_hw_init(struct OBJGPU *adev) {
    // GOOD: Uses abstracted I/O
    os_prim_write32(adev->mmio_base + mmVM_L2_CNTL, 0);
    
    // GOOD: Logging agnÃ³stico
    os_prim_log("GMC: Initialized\n");
    
    return 0;
}
```

#### âœ… Pattern: Error Handling

```c
// Always check returns
int status = os_prim_pci_find_device(0x1002, 0x9806, &handle);
if (status < 0) {
    os_prim_log("ERROR: No AMD GPU found\n");
    return -1;
}

// Validate state before hardware access
if (!adev->mmio_base) {
    os_prim_log("ERROR: MMIO not mapped\n");
    return -1;
}
```

### C. RMAPI Layer

#### âœ… Pattern: Userland IPC

```c
// rmapi_server.c - agnÃ³stico
#include "../os-interface/os_abstract_ipc.h"

void rmapi_server_main(void) {
    os_ipc_server_t server = os_ipc_server_create(OS_IPC_UNIX_SOCKET,
                                                 "/tmp/amdgpu.sock", 16);
    
    while (1) {
        os_ipc_connection_t *conn = os_ipc_server_accept(server, 0);
        if (!conn) continue;
        
        rmapi_message_t msg;
        if (os_ipc_recv(conn, &msg, sizeof(msg), 0) > 0) {
            rmapi_process_request(&msg);
            os_ipc_send(conn, &msg, sizeof(msg));
        }
        
        os_ipc_disconnect(conn);
    }
}
```

---

## ðŸŽ¯ PATRONES DE IMPLEMENTACIÃ“N

### Pattern 1: Platform-Specific Initialization

```c
// In each os_primitives_*.c

static int os_prim_init_platform_specific(void) {
    // Linux: Setup /dev/mem access
    // Haiku: Load device_manager, PCI module
    // FreeBSD: Verify /dev/io permissions
    
    // Common: Log success
    os_prim_log("Platform initialized\n");
    return 0;
}
```

### Pattern 2: Graceful Degradation

```c
int os_prim_pci_find_device(uint16_t vendor, uint16_t device, void **handle) {
    // Try real HW first
    if (try_real_pci_scan(vendor, device, handle) == 0) {
        os_prim_log("Found real device\n");
        return 0;
    }
    
    // Fallback to simulation
    os_prim_log("WARNING: Using simulated device\n");
    *handle = (void *)0x9806;  // Wrestler APU
    return 0;
}
```

### Pattern 3: Compile-Time Feature Detection

```c
// os_primitives.h
#if defined(__linux__)
    #define OS_HAS_REAL_MMIO 1
    #define OS_HAS_SYSFS 1
#elif defined(__HAIKU__)
    #define OS_HAS_DEVICE_MANAGER 1
#elif defined(__FreeBSD__)
    #define OS_HAS_DEV_IO 1
#endif

// In implementation:
#if OS_HAS_REAL_MMIO
    fd = open("/dev/mem", O_RDWR | O_SYNC);
#else
    // Simulation
#endif
```

### Pattern 4: Thread Safety

```c
// Every mutable global should be protected
static pthread_mutex_t g_state_lock = PTHREAD_MUTEX_INITIALIZER;
static int g_device_count = 0;

int get_device_count(void) {
    pthread_mutex_lock(&g_state_lock);
    int count = g_device_count;
    pthread_mutex_unlock(&g_state_lock);
    return count;
}
```

---

## ðŸ§ª TESTING MULTIPLATAFORMA

### Test Strategy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Unit Tests (abstracted)â”‚ â† Test abstractions themselves
â”‚  - os_log()             â”‚
â”‚  - os_mutex_lock()      â”‚
â”‚  - os_ipc_send()        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ IP Block Tests (HAL layer)    â”‚ â† Test GPU logic
â”‚ - gmc_v10_hw_init()           â”‚
â”‚ - gfx_v10_hw_init()           â”‚
â”‚ - Register reads/writes       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Integration Tests (full stack) â”‚ â† Test workflows
â”‚ - rmapi_server + client       â”‚
â”‚ - Memory alloc/free cycle     â”‚
â”‚ - IPC round-trip              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Platform Tests (per SO)        â”‚ â† Test SO specifics
â”‚ Linux:   valgrind, strace     â”‚
â”‚ Haiku:   Haiku emulator       â”‚
â”‚ FreeBSD: FreeBSD VM           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Makefile Multi-platform

```makefile
# Makefile - Ejemplo

ifeq ($(OS),linux)
  OS_PRIM_SRC := kernel-amd/os-primitives/linux/os_primitives_linux.c
  CFLAGS += -D__LINUX__
else ifeq ($(OS),haiku)
  OS_PRIM_SRC := kernel-amd/os-primitives/haiku/os_primitives_haiku.c
  CFLAGS += -D__HAIKU__ $(HAIKU_CFLAGS)
else ifeq ($(OS),freebsd)
  OS_PRIM_SRC := kernel-amd/os-primitives/freebsd/os_primitives_freebsd.c
  CFLAGS += -D__FREEBSD__
endif

all: libamdgpu.so rmapi_server tests

tests:
	$(CC) -o tests/test_os_primitives tests/test_os_primitives.c $(OS_PRIM_SRC)
	$(CC) -o tests/test_gmc tests/test_gmc_v10.c src/amd/gmc_v10.c $(OS_PRIM_SRC)
```

### Test Checklist

```c
// tests/test_agnosis.c

void test_no_linux_headers_in_hal(void) {
    // Compile HAL without Linux headers
    // Should work on any platform
}

void test_os_primitives_api_consistent(void) {
    // Same behavior on Linux, Haiku, FreeBSD
    uint32_t val = os_prim_read32(addr);
    assert(val >= 0);
    
    os_prim_write32(addr, 0xDEADBEEF);
    uint32_t val2 = os_prim_read32(addr);
    assert(val2 == 0xDEADBEEF);
}

void test_ipc_works_across_platforms(void) {
    // Unix socket works on Linux, Haiku, FreeBSD
    // Should pass on all platforms
}
```

---

## âœ… CHECKLIST DE AGNOSIS

### Headers & Includes

- [ ] HAL headers NOT including SO-specific includes
- [ ] RMAPI headers NOT including SO-specific includes  
- [ ] All SO-specific includes behind abstraction layer
- [ ] Common code uses only os_abstract_*.h headers

### Implementation Completeness

- [ ] **Linux**: os_primitives_linux.c fully implemented
- [ ] **Haiku**: os_primitives_haiku.c fully implemented
- [ ] **FreeBSD**: os_primitives_freebsd.c fully implemented
- [ ] IPC layer: Unix sockets working on all platforms
- [ ] Threading layer: All primitives implemented
- [ ] Logging layer: Multi-target support

### Error Handling

- [ ] All os_prim_* functions validate inputs
- [ ] Fallback to simulation when HW not available
- [ ] Graceful degradation (no crashes)
- [ ] Meaningful error messages

### Thread Safety

- [ ] Global state protected by mutexes
- [ ] No race conditions in MMIO access
- [ ] IPC messages properly synchronized
- [ ] Logging thread-safe

### Documentation

- [ ] Each abstraction layer documented
- [ ] Platform-specific notes in comments
- [ ] Example code for each OS-primitive
- [ ] Known limitations documented

### Testing

- [ ] Unit tests compile on all platforms
- [ ] Integration tests pass on all platforms
- [ ] Memory leak detection (valgrind)
- [ ] No uninitialized variable usage

### Code Quality

- [ ] No compiler warnings with -Wall -Wextra
- [ ] MISRA C compliance (where applicable)
- [ ] Resource cleanup in error paths
- [ ] No hardcoded paths (use configurable)

---

## ðŸ”§ TROUBLESHOOTING AGNOSIS ISSUES

### Problema: "Works on Linux but not Haiku"

**Cause:** Probablemente usando syscalls Linux-specific

```c
// âŒ BAD: Linux-specific
fd = open("/dev/mem", ...);
ioctl(fd, IOCTL_SOMETHING, ...);

// âœ… GOOD: Use abstraction
void *addr = os_prim_pci_map_resource(handle, bar);
```

**Fix:** Replace con os_primitives abstractions

### Problema: "Segmentation fault on FreeBSD"

**Cause:** Asumiendo page size or memory layout

```c
// âŒ BAD: Assumes 4K pages
size_t page_size = 4096;

// âœ… GOOD: Query system
size_t page_size = sysconf(_SC_PAGE_SIZE);
```

### Problema: "Logging doesn't appear"

**Cause:** Logger no inicializado

```c
// âœ… GOOD: Always initialize
os_logger_config_t cfg = { .target = OS_LOG_TARGET_STDERR, ... };
os_logger_init(&cfg);

// Then:
OS_LOG_INFO("TEST", "Message appears\n");
```

---

## ðŸ“š REFERENCIAS

### Documentos de DiseÃ±o
- `MAESTRO.md` - Plan maestro general
- `ROADMAP_ORDENADO.md` - Pasos de implementaciÃ³n

### Headers de AbstracciÃ³n
- `kernel-amd/os-primitives/os_primitives.h` - Basics
- `kernel-amd/os-interface/os_abstract_ipc.h` - Communication
- `kernel-amd/os-interface/os_abstract_threading.h` - Sync primitives
- `kernel-amd/os-interface/os_abstract_logging.h` - Logging

### Implementaciones
- `kernel-amd/os-primitives/linux/` - Linux
- `kernel-amd/os-primitives/haiku/` - Haiku  
- `kernel-amd/os-primitives/freebsd/` - FreeBSD

---

## ðŸŽ“ CONCLUSIÃ“N

**Key principles para agnosis:**

1. **Layer your abstractions** - Separate HW logic from OS logic
2. **Graceful degradation** - Work with simulation if HW unavailable
3. **Platform-specific implementations** - One .c file per OS
4. **Consistent APIs** - Same function signatures everywhere
5. **Thread safety** - Protect shared state
6. **Comprehensive logging** - Debug multi-platform issues
7. **Testable design** - Unit test abstractions independently

**El cÃ³digo agnÃ³stico NO significa:**
- Ignorar diferencias de SO
- Usar #ifdef everywhere
- Fallos silenciosos

**El cÃ³digo agnÃ³stico SÃ significa:**
- Abstracciones claras y consistentes
- Implementaciones SO-especÃ­ficas donde necesario
- Fallbacks graceful a simulaciÃ³n
- DocumentaciÃ³n clara de limitaciones

**Â¡Listo para ser verdaderamente multi-plataforma!** ðŸš€

---

*Proyecto: AMDGPU_Abstracted (HIT Edition)*  
*Actualizado: 2024-01-16*  
*Status: Agnosis COMPLETADA con mejores prÃ¡cticas*
